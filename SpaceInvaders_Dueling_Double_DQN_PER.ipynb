{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SpaceInvaders_Dueling_Double_DQN_PER.ipynb","provenance":[{"file_id":"1gjcfL62XHXAPJupsM9z9IfesOUyThXFq","timestamp":1587447542091},{"file_id":"10-6XoXngJvfWgzi7xGhZIiLaK_HuCK-U","timestamp":1586983375211},{"file_id":"https://github.com/wandb/qualcomm-contest/blob/master/SpaceInvaders_Baseline.ipynb","timestamp":1586827628445}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KfOuv88IHJTV"},"source":["# Space Invaders\n","\n","# Weights & Biases x Qualcomm - SpaceInvaders Challenge\n","\n","We’re excited to announce the W&B [SpaceInvaders](https://gym.openai.com/envs/SpaceInvaders-v0/) Challenge, a reinforcement learning competition. Your goal is to train reinforcement learning agents in OpenAI's gym environment. The contestants with the top 3 scores will receive prizes and be invited to present their solutions to the community. The challenge is open to Qualcomm employees only.\n","\n","This notebook contains code for loading the gym environment, preprocessing data, and calculating & logging the cumulative average reward metrics.\n","\n","![](https://thumbs.gfycat.com/CookedFriendlyAntarcticfurseal-size_restricted.gif)\n","\n","## Running this notebook\n","1. Click \"Open in playground\" to create a copy of this notebook for yourself.\n","2. Save a copy in Google Drive for yourself.\n","3. To enable a GPU, please click Edit > Notebook Settings. Change the \"hardware accelerator\" to GPU.\n","4. Step through each section, pressing play on the code blocks to run the cells.\n","5. Add your own model code.\n","\n","## Submissions\n","You may submit your entries [here](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/submit). You'll need a Weights & Biases account to make submissions.\n","\n","Each run must include the following files:\n","\n","- Model file generated by [wandb.save()](https://docs.wandb.com/library/python/save)\n","- Model training script (.py file or notebook)\n","- Any other files necessary to recreate the model\n","\n","**Please ensure that you log your model file and all files necessary to recreate the model in your run using [wandb.save()](https://docs.wandb.com/library/python/save). Without this, we will be unable to evaluate your model.**\n","\n","Also please ensure that your code is not in a public repo, but is visible to us by adding 'lavanyashukla' as a collaborator to your repo. We will use the model saved in the submitted run to recreate the model and evaluate it across the 5 random seeds.\n","\n","## Evaluation\n","Your objective is to maximize the best 100-episode average reward. This means your model will play the game for 100 episodes, and we will calculate a running average of the cumulative reward gained as each of the episodes is played. After 100 episodes, this cumulative running average will be your final score for the run.\n","\n","We encourage you to submit as many runs as you like. To verify results, we will pick the top 5-10 submissions as ranked by the evaluation metric (best 100-episode average reward), and run these agents through the SpaceInvaders environment. We will evaluate how the agents do across 5 randomly generated seeds. This means, your agent will be run for 100 episodes with 5 different seeds and generate a best 100-episode average reward for each seed. We will take the average of these scores to get the final best 100-episode average reward.\n","\n","Entries will be ranked from highest to lowest by the best 100-episode average reward received across the 5 seeds.\n","\n","For more details, please visit the [competition website](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o-uAdQfWkjIh","outputId":"c96d15b1-f581-4ae8-c39f-94240980f23b","executionInfo":{"status":"ok","timestamp":1588283773961,"user_tz":420,"elapsed":32965,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":498}},"source":["!pip install gym pyvirtualdisplay -qq\n","!pip install folium==0.2.1\n","!apt-get install -y xvfb python-opengl ffmpeg -qq\n","\n","!apt-get update -qq\n","!apt-get install cmake -qq\n","!pip install --upgrade setuptools -qq\n","!pip install ez_setup -qq"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting folium==0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n","\r\u001b[K     |████▊                           | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n","Building wheels for collected packages: folium\n","  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for folium: filename=folium-0.2.1-cp36-none-any.whl size=79979 sha256=9f73589865eddbf7aa1b923ebb4f1065ef6528cf1b609bb8521d736bf4a560d8\n","  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n","Successfully built folium\n","Installing collected packages: folium\n","  Found existing installation: folium 0.8.3\n","    Uninstalling folium-0.8.3:\n","      Successfully uninstalled folium-0.8.3\n","Successfully installed folium-0.2.1\n","Selecting previously unselected package python-opengl.\n","(Reading database ... 144568 files and directories currently installed.)\n","Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-1) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n","Setting up python-opengl (3.1.0+dfsg-1) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","  Building wheel for ez-setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gn_FFMWRsM8f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"3aa09b87-26d1-4d00-c1da-5fd71bf37a97","executionInfo":{"status":"ok","timestamp":1588283789262,"user_tz":420,"elapsed":12046,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}}},"source":["!pip install --upgrade wandb -qq"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 8.2MB/s \n","\u001b[K     |████████████████████████████████| 112kB 31.2MB/s \n","\u001b[K     |████████████████████████████████| 102kB 13.4MB/s \n","\u001b[K     |████████████████████████████████| 102kB 9.9MB/s \n","\u001b[K     |████████████████████████████████| 460kB 23.0MB/s \n","\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n","\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"23TOba33L4qf","outputId":"5693aaa6-0d6a-4018-d4b4-5643abe08be5","executionInfo":{"status":"ok","timestamp":1588233421072,"user_tz":420,"elapsed":1703,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":335}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Thu Apr 30 07:57:00 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ms0B7dnLHJTc","outputId":"0e5e8c01-ea6b-4f21-b34a-3c4c8bcd4aef","executionInfo":{"status":"ok","timestamp":1588283833899,"user_tz":420,"elapsed":30374,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":148}},"source":["import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(30)\n","\n","import numpy as np\n","import random\n","import math\n","import glob\n","import io\n","import os\n","import cv2\n","import base64\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from collections import deque\n","from datetime import datetime\n","import keras\n","\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","from pyvirtualdisplay import Display\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","import tensorflow as tf\n","\n","# import wandb\n","import wandb\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"wXDlF6cdHJTj"},"source":["## Preprocessing - crop images, convert them to 1D black and white image tensors\n","\n","- Image dimensions - (210, 160, 3)\n","- Output dimensions - (88, 80, 1)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"29CSBYkPHJTl","colab":{}},"source":["color = np.array([210, 164, 74]).mean()\n","\n","def preprocess_frame(obs):\n","    # Crop and resize\n","    img = obs[25:201:2, ::2]\n","\n","    # Convert to greyscale\n","    img = img.mean(axis=2).astype(np.uint8)\n","\n","    # Improve contrast\n","    img[img==color] = 0\n","    \n","    # Reshape to 80*80*1\n","    img = img.reshape(88,80)\n","\n","    return np.atleast_3d(img)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y1qZntlnHJTs"},"source":["## Initialize gym environment and explore game screens\n"]},{"cell_type":"code","metadata":{"id":"S4nYnj42iYY1","colab_type":"code","outputId":"5bbe0b20-02f6-4d03-8a43-03baf37af1af","executionInfo":{"status":"ok","timestamp":1588283865088,"user_tz":420,"elapsed":1229,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["env = gym.make(\"SpaceInvaders-v0\")\n","state_size = env.observation_space.shape[0]\n","action_size = env.action_space.n\n","print(\"Actions available(%d): %r\"%(env.action_space.n, env.env.get_action_meanings()))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Actions available(6): ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jnbrjWstHJTu","outputId":"d068b8ce-ca32-46f0-d40d-6daeb1064f3e","executionInfo":{"status":"ok","timestamp":1588283867689,"user_tz":420,"elapsed":1018,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["observation = env.reset()\n","# Game Screen\n","for i in range(11):\n","  if i > 9:\n","    plt.imshow(observation)\n","    plt.show()\n","  observation, _, _, _ = env.step(1)"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_Ma31y4wFpst","outputId":"e77b1b40-696a-4d80-a7ed-fe08d841769e","executionInfo":{"status":"ok","timestamp":1588283871001,"user_tz":420,"elapsed":1074,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":268}},"source":["# Preprocessed Game Screen\n","obs_preprocessed = preprocess_frame(observation).reshape(88,80)\n","plt.imshow(obs_preprocessed)\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"P8kcKkqbOMgW","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"J4eZ3NU-OMqv","colab_type":"code","colab":{}},"source":["# **** Caution: Do not modify this cell ****\n","# initialize total reward across episodes\n","cumulative_reward = 0\n","episode = 0\n","\n","def evaluate(episodic_reward):\n","  '''\n","  Takes in the reward for an episode, calculates the cumulative_avg_reward\n","    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n","    Called after playing each episode. See example below.\n","\n","  Arguments:\n","    episodic_reward - reward received after playing current episode\n","  '''\n","  global episode\n","  global cumulative_reward\n","  episode += 1\n","  print(\"Episode: %d\"%(episode))\n","\n","  # your models will be evaluated on 100-episode average reward\n","  # therefore, we stop logging after 100 episodes\n","  if (episode > 100):\n","    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n","    return\n","\n","  # log total reward received in this episode to wandb\n","  wandb.log({'episodic_reward': episodic_reward})\n","\n","  # add reward from this episode to cumulative_reward\n","  cumulative_reward += episodic_reward\n","\n","  # calculate the cumulative_avg_reward\n","  # this is the metric your models will be evaluated on\n","  cumulative_avg_reward = cumulative_reward/episode\n","  print(\"episode_reward:\",episodic_reward,\"avg_reward:\",cumulative_avg_reward)\n","\n","  # log cumulative_avg_reward over all episodes played so far\n","  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2tXWpRTdirOQ","colab_type":"text"},"source":["### Play a random game, log reward and gameplay video in wandb"]},{"cell_type":"markdown","metadata":{"id":"EdJtsS5dd9hx","colab_type":"text"},"source":["In this section we'll show you how to save a model in Weights & Biases. This is necessary in order for us to evaluate your model.\n","\n","Let's train a very basic model to start."]},{"cell_type":"code","metadata":{"id":"RYMhp_lgQMsA","colab_type":"code","colab":{}},"source":["class SumTreeNode:\n","  def __init__(self, left, right, is_leaf=False, idx=None):\n","    self.left = left\n","    self.right = right\n","    self.is_leaf = is_leaf\n","    self.value = 0\n","    self.idx = idx\n","    self.parent = None\n","    if not self.is_leaf:\n","      self.value = self.left.value + self.right.value\n","    if left is not None:\n","      left.parent = self\n","    if right is not None:\n","      right.parent = self\n","\n","  @classmethod\n","  def create_leaf_node(cls,value,idx):\n","    leaf = cls(None,None,is_leaf=True,idx=idx)\n","    leaf.value = value\n","    return leaf\n","\n","class SumTree:\n","  def __init__(self, inputs):\n","    nodes = [SumTreeNode.create_leaf_node(val, idx) for idx, val in enumerate(inputs)]\n","    self.leaf_nodes = nodes\n","    while len(nodes) > 1:\n","      nodes_itr = iter(nodes)\n","      nodes = [SumTreeNode(*pair) for pair in zip(nodes_itr, nodes_itr)]\n","    self.base_node = nodes[0]\n","\n","  def retrieve_node(self, value):\n","    val = value\n","    node = self.base_node\n","    while not node.is_leaf:\n","      if node.left.value >= val:\n","        node = node.left\n","      else:\n","        val -= node.left.value\n","        node = node.right\n","    return node\n","\n","  def update(self, idx, new_value):\n","    node = self.leaf_nodes[idx]\n","    change = new_value - node.value\n","    node.value = new_value\n","    while node.parent is not None:\n","      node = node.parent\n","      node.value += change\n","\n","  def get_base_node_value(self):\n","    return self.base_node.value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zviHV0KNVhXF","colab_type":"code","colab":{}},"source":["class PrioritizedExperienceReplay(object):\n","  def __init__(self, max_size=1000000, train_min_frames=50000, train_max_frames=6000000, batch_size=32, state_frames_size=4, state_frame_height=88, state_frame_width=80):\n","    self.max_size = max_size\n","    self.train_min_frames = train_min_frames\n","    self.train_max_frames = train_max_frames\n","    self.frame_height = state_frame_height\n","    self.frame_width = state_frame_width\n","    self.frame_history = state_frames_size\n","    self.batch_size = batch_size    \n","    self.current_idx = 0\n","    self.total_count = 0\n","\n","    self.beta_start = 0.4\n","    self.beta_end = 1\n","    self.beta_slope = (self.beta_end - self.beta_start) / self.train_max_frames\n","    self.beta_intercept = self.beta_start - (self.beta_slope * self.train_min_frames)\n","    self.alpha = 0.6\n","    self.min_priority = 0.01\n","    self.sum_tree = SumTree([0 for i in range(self.max_size)])\n","\n","    self.actions = np.empty(self.max_size, dtype=np.int8)\n","    self.rewards = np.empty(self.max_size, dtype=np.float32)\n","    self.terminal_flags = np.empty(self.max_size, dtype=np.bool)\n","    self.image_frames = np.empty((self.max_size, self.frame_height, self.frame_width), dtype=np.uint8)\n","\n","    self.states = np.empty((self.batch_size, self.frame_history, self.frame_height, self.frame_width), dtype=np.uint8)\n","    self.new_states = np.empty((self.batch_size, self.frame_history, self.frame_height, self.frame_width), dtype=np.uint8)\n","    self.batch_indices = np.empty(self.batch_size, dtype=np.int32)\n","    self.importance_weights = np.empty(self.batch_size, dtype=np.float32)\n","\n","  def get_adjusted_priority(self, priority_value):\n","    return np.power(priority_value + self.min_priority, self.alpha)\n","\n","  def add_experience(self, frame, action, reward, terminal_flag, priority_value):\n","    self.image_frames[self.current_idx, ...] = frame\n","    self.actions[self.current_idx] = action\n","    self.rewards[self.current_idx] = reward\n","    self.terminal_flags[self.current_idx] = terminal_flag    \n","    self.sum_tree.update(self.current_idx, self.get_adjusted_priority(priority_value))\n","    self.current_idx +=1 \n","\n","    if self.current_idx >= self.max_size:\n","      self.current_idx = 0\n","\n","    if self.total_count + 1 < self.max_size:\n","      self.total_count += 1\n","    else:\n","      self.total_count = self.max_size\n","\n","  # update_batch() should be called only after get_mini_batch() is invoked\n","  # else td_error will be updated for wrong batch_indices\n","  def update_batch(self, td_error):\n","    for idx, batch_idx in enumerate(self.batch_indices):\n","      self.sum_tree.update(batch_idx, self.get_adjusted_priority(td_error[idx]))  \n","\n","  def get_indices_and_weights(self, frame_nos):    \n","    base_node_val = self.sum_tree.get_base_node_value()\n","    every_range_len = base_node_val / self.batch_size\n","    for i in range(self.batch_size):      \n","      while True:\n","        sample_priority_val = (random.random() * every_range_len) + (i * every_range_len)\n","        sample_node = self.sum_tree.retrieve_node(sample_priority_val) \n","        if sample_node.idx < self.frame_history:\n","          continue       \n","        if sample_node.idx >= self.total_count:\n","          continue\n","        if sample_node.idx >= self.current_idx and (sample_node.idx - self.frame_history) <= self.current_idx:\n","          continue\n","        if self.terminal_flags[sample_node.idx - self.frame_history:sample_node.idx].any():\n","          continue\n","        break\n","      self.batch_indices[i] = sample_node.idx\n","      norm_probability = sample_node.value / base_node_val\n","      self.importance_weights[i] = (self.total_count * norm_probability)\n","    beta = self.beta_intercept + (self.beta_slope * frame_nos)\n","    self.importance_weights = np.power(self.importance_weights, -beta)\n","    self.importance_weights = self.importance_weights / np.max(self.importance_weights)\n","\n","  def get_mini_batch(self, frame_nos):\n","    if self.total_count < self.frame_history:\n","      raise(\"Insufficient experience\")    \n","    self.get_indices_and_weights(frame_nos)\n","    for idx, batch_idx in enumerate(self.batch_indices):\n","      self.states[idx] = self.image_frames[batch_idx - self.frame_history:batch_idx, ...]\n","      self.new_states[idx] = self.image_frames[(batch_idx - self.frame_history)+1:batch_idx+1, ...]\n","    return np.transpose(self.states, axes=(0,2,3,1)), self.actions[self.batch_indices], self.rewards[self.batch_indices], np.transpose(self.new_states, axes=(0,2,3,1)), self.terminal_flags[self.batch_indices], self.importance_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C73Gf-XeS70E","colab_type":"code","colab":{}},"source":["class DuelingDoubleDQNModel(tf.keras.Model):\n","  def __init__(self, action_size, hidden_units=512, batch_size=32, state_frames_size=4, state_frame_height=88, state_frame_width=80):\n","    super(DuelingDoubleDQNModel, self).__init__()      \n","    self.action_size = action_size\n","    self.batch_size = batch_size\n","    self.hidden_units = hidden_units    \n","    self.state_frames_size = state_frames_size\n","    self.state_frame_height = state_frame_height\n","    self.state_frame_width = state_frame_width\n","        \n","    self.input_layer = tf.keras.layers.InputLayer(input_shape=[self.state_frame_height, self.state_frame_width, self.state_frames_size], batch_size=self.batch_size, name=\"input\")\n","    self.norm_input = tf.keras.layers.Lambda(lambda x : x / 255.0)               \n","    self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=[8,8], strides=4,\n","                                        kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2),\n","                                        padding=\"valid\", activation=tf.keras.activations.relu, use_bias=False, name='conv1')\n","    self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=[4,4], strides=2,\n","                                        kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2),\n","                                        padding=\"valid\", activation=tf.keras.activations.relu, use_bias=False, name='conv2')\n","    self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], strides=1,\n","                                        kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2),\n","                                        padding=\"valid\", activation=tf.keras.activations.relu, use_bias=False, name='conv3')\n","    self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=[3,3], strides=1,\n","                                        kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2),\n","                                        padding=\"valid\", activation=tf.keras.activations.relu, use_bias=False, name='conv4')    \n","    self.flatten = tf.keras.layers.Flatten()\n","    self.value_dense = tf.keras.layers.Dense(units=hidden_units, activation=tf.keras.activations.relu, \n","                                             kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2), name='value_dense')\n","    self.advantage_dense = tf.keras.layers.Dense(units=hidden_units, activation=tf.keras.activations.relu, \n","                                             kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2), name='advantage_dense')\n","    self.value_out = tf.keras.layers.Dense(units=1, kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2), name='value_out')    \n","    self.advantage_out = tf.keras.layers.Dense(units=self.action_size, kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2), name='advantage_out')\n","    self.advantage_reduce = tf.keras.layers.Lambda(lambda x : x - tf.reduce_mean(x))\n","    self.Q_values = tf.keras.layers.Add()\n","\n","  @tf.function\n","  def call(self, state_frames):\n","    inputs = self.input_layer(tf.cast(state_frames, tf.float32))\n","    norm_inputs = self.norm_input(inputs)    \n","    conv_output1 = self.conv1(norm_inputs)\n","    conv_output2 = self.conv2(conv_output1)\n","    conv_output3 = self.conv3(conv_output2)\n","    conv_output4 = self.conv4(conv_output3)\n","    flatten_output = self.flatten(conv_output4)\n","    val_dense = self.value_dense(flatten_output)\n","    adv_dense = self.advantage_dense(flatten_output)\n","    val_out = self.value_out(val_dense)\n","    adv_out = self.advantage_out(adv_dense)\n","    norm_adv_out = self.advantage_reduce(adv_out)    \n","    q_vals = self.Q_values([val_out, norm_adv_out])        \n","    return q_vals"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXRmlR3cY8ki","colab_type":"code","colab":{}},"source":["class DuelingDoubleDQN:\n","  def __init__(self, epsilon_greedy, action_size, hidden_units=512, learning_rate=0.0000625, batch_size=32, state_frames_size=4, state_frame_height=88, state_frame_width=80):    \n","    self.epsilon_greedy = epsilon_greedy\n","    self.action_size = action_size    \n","    self.model = DuelingDoubleDQNModel(action_size, hidden_units, batch_size, state_frames_size, state_frame_height, state_frame_width)\n","    self.loss = tf.keras.losses.Huber()\n","    self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)    \n","  \n","  def get_Q_values(self, input):\n","    return self.model(input)    \n","  \n","  def train(self, states, actions, target_Q, importance_sampling_weights):        \n","    with tf.GradientTape() as tape:\n","      predicted_Q_values = self.get_Q_values(states)\n","      predicted_Q = tf.reduce_sum(tf.multiply(predicted_Q_values, tf.one_hot(actions, self.action_size, dtype=tf.float32)), axis=1)\n","      predicted_Q = tf.expand_dims(predicted_Q, 1)\n","      target_Q = tf.convert_to_tensor(target_Q)\n","      target_Q = tf.expand_dims(target_Q, 1)      \n","      importance_sampling_weights = tf.convert_to_tensor(importance_sampling_weights)            \n","      loss = self.loss.__call__(y_true=target_Q, y_pred=predicted_Q, sample_weight=importance_sampling_weights)\n","    variables = self.model.trainable_variables    \n","    gradients = tape.gradient(loss, variables)    \n","    self.optimizer.apply_gradients(zip(gradients, variables))\n","    return predicted_Q_values, loss\n","\n","  def get_action(self, input, frame_nos, evaluation=False):\n","    Q_Values = self.get_Q_values(np.expand_dims(input, axis=0))\n","    epsilon = self.epsilon_greedy.get_epsilon(frame_nos, evaluation)\n","    if np.random.rand(1) < epsilon:\n","      return np.random.randint(0, self.action_size), Q_Values\n","    else:            \n","      best_action = tf.argmax(Q_Values, 1)\n","      return best_action, Q_Values      \n","\n","  def copy_weights(self, main_dqn):\n","    variables_1 = self.model.trainable_variables\n","    variables_2 = main_dqn.model.trainable_variables\n","    for v1, v2 in zip(variables_1, variables_2):\n","      v1.assign(v2.numpy())\n","\n","  def save_model(self, name):\n","    self.model.save(name)\n","\n","  def load_model(self, name):\n","    self.model = tf.keras.models.load_model(name)\n","    print(self.model.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwUK5t1_oUvp","colab_type":"code","colab":{}},"source":["def huber_loss(loss):\n","  return 0.5 * loss ** 2 if abs(loss) < 1.0 else abs(loss) - 0.5\n","\n","def get_target_Q(main_dqn, target_dqn, batch_size, gamma, new_states, rewards, terminal_flags):\n","  main_dqn_Q = main_dqn.get_Q_values(new_states)\n","  arg_Q_max = tf.argmax(main_dqn_Q, 1)\n","  target_dqn_Q = target_dqn.get_Q_values(new_states)  \n","  double_Q = target_dqn_Q.numpy()[range(0,batch_size), arg_Q_max]\n","  target_Q = rewards + (gamma * double_Q * (1 - terminal_flags))\n","  return target_Q\n","\n","def get_td_error(target_Q, predicted_Q, actions, batch_size):  \n","  td_error = [huber_loss(target_Q[i] - predicted_Q.numpy()[i, actions[i]]) for i in range(batch_size)]\n","  return td_error\n","\n","def train_main_dqn(main_dqn, target_dqn, experience_replay, batch_size, gamma, frame_nos):\n","  states, actions, rewards, new_states, terminal_flags, imp_weights = experience_replay.get_mini_batch(frame_nos)      \n","  target_Q = get_target_Q(main_dqn, target_dqn, batch_size, gamma, new_states, rewards, terminal_flags)  \n","  predicted_Q, loss = main_dqn.train(states, actions, target_Q, imp_weights)\n","  # Calculate the TD-Error for updating the experience replay priorities  \n","  # Update the experience replay with TD-error\n","  experience_replay.update_batch(get_td_error(target_Q, predicted_Q, actions, batch_size))\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaGYBDcFzCaZ","colab_type":"code","colab":{}},"source":["class epsilonGreedy(object):\n","  def __init__(self, replay_min_frames, replay_max_frames, train_max_frames):    \n","    self.epsilon_start = 1.0\n","    self.epsilon_end = 0.1\n","    self.epsilon_min = 0.01\n","    self.epsilon_eval = 0.05\n","    self.replay_max_frames = replay_max_frames\n","    self.replay_min_frames = replay_min_frames\n","    self.train_max_frames = train_max_frames\n","    self.epsilon_slope = -(self.epsilon_start - self.epsilon_end)/self.replay_max_frames\n","    self.epsilon_intercept = self.epsilon_start - (self.epsilon_slope * self.replay_min_frames)\n","    self.epsilon_slope_2 = -(self.epsilon_end - self.epsilon_min)/(self.train_max_frames - self.replay_max_frames - self.replay_min_frames)\n","    self.epsilon_intercept_2 = self.epsilon_min - (self.epsilon_slope_2 * self.train_max_frames)  \n","\n","  def get_epsilon(self, frame_nos, evaluation=False):\n","    epsilon = 0\n","    if evaluation:\n","      epsilon = self.epsilon_eval\n","    elif frame_nos < self.replay_min_frames:\n","      epsilon = self.epsilon_start\n","    elif frame_nos >= self.replay_min_frames and frame_nos < (self.replay_min_frames + self.replay_max_frames):\n","      epsilon = (frame_nos * self.epsilon_slope) + self.epsilon_intercept\n","    elif frame_nos >= (self.replay_min_frames + self.replay_max_frames):\n","      epsilon = (frame_nos * self.epsilon_slope_2) + self.epsilon_intercept_2\n","    return epsilon    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxQkC1RR7jOd","colab_type":"code","colab":{}},"source":["class Atari_Env(object):\n","  def __init__(self, atari_env, no_op_steps = 30, frame_history = 4):\n","    self.env = gym.make(atari_env)\n","    self.state = None\n","    self.remaining_lives = 0\n","    self.no_op_steps = no_op_steps\n","    self.frame_history = frame_history\n","\n","  def reset(self, evaluation=False):\n","    frame = self.env.reset()\n","    self.remaining_lives = 0\n","    terminal_life_lost = True\n","    if evaluation:\n","      for _ in range(random.randint(1, self.no_op_steps)):\n","        frame, _, _, _ = self.env.step(0) #Do nothing\n","    processed_frame = preprocess_frame(frame)    \n","    self.state = np.repeat(processed_frame, self.frame_history, axis=2)\n","    return terminal_life_lost\n","\n","  def step(self, action):    \n","    new_frame, reward, terminal, info = self.env.step(action)\n","    if info['ale.lives'] < self.remaining_lives:\n","      terminal_life_lost = True\n","    else:\n","      terminal_life_lost = terminal\n","    self.remaining_lives = info['ale.lives']\n","    processed_new_frame = preprocess_frame(new_frame)\n","    new_state = np.append(self.state[:,:,1:], processed_new_frame, axis=2)\n","    self.state = new_state\n","    return processed_new_frame, reward, terminal, terminal_life_lost, new_frame\n","\n","  def eval_reset(self):\n","    frame = self.env.reset()    \n","    for _ in range(random.randint(0, self.no_op_steps)):\n","      frame, _, _, _ = self.env.step(0)\n","    processed_frame = preprocess_frame(frame)    \n","    self.state = np.repeat(processed_frame, self.frame_history, axis=2)\n","    return self.state\n","\n","  def eval_step(self, action, frame_skip):\n","    prev_frame = None\n","    new_frame, reward, terminal, _ = self.env.step(action)        \n","    for _ in range(1, frame_skip):\n","      if not terminal:\n","        prev_frame = new_frame\n","        new_frame, r, terminal, _ = self.env.step(action)\n","        reward += r\n","\n","    if prev_frame is not None:\n","      new_frame = np.maximum.reduce([new_frame, prev_frame])    \n","        \n","    processed_new_frame = preprocess_frame(new_frame)\n","    self.state = np.append(self.state[:,:,1:], processed_new_frame, axis=2)\n","    return self.state, reward, terminal            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6biSELV---Pj","colab_type":"code","colab":{}},"source":["def clip_reward(reward):\n","  if reward > 0:\n","    return 1\n","  elif reward == 0:\n","    return 0\n","  else:\n","    return -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwhhcFLO_QNe","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","\n","MAX_EPISODE_FRAMES = 18000\n","TARGET_NETWORK_UPDATE_FREQ = 10000\n","GAMMA = 0.99\n","EVALUATION_FREQUENCY = 200000\n","EVALUATION_STEPS = 10000\n","EXPERIENCE_REPLAY_MIN_SIZE = 50000\n","EXPERIENCE_REPLAY_MAX_SIZE = 1000000\n","MAX_FRAMES = 3000000\n","NO_OP_STEPS = 30\n","UPDATE_FREQ = 4\n","HIDDEN = 512\n","LEARNING_RATE = 0.0000625\n","BATCH_SIZE = 32"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ADF7X-pgTXTS","colab_type":"text"},"source":["The below code block is used to train the model. Skip this in-case of evaluation of a pre-trained model."]},{"cell_type":"code","metadata":{"id":"cV2b4DUtCtNU","colab_type":"code","outputId":"69b81805-318b-4ae6-d1f8-a04ec433593a","executionInfo":{"status":"ok","timestamp":1587929918064,"user_tz":420,"elapsed":1321289,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def execute_training():\n","  # initialize a new wandb run\n","  wandb.init(project=\"qualcomm\")\n","  print(\"Wandb Run Dir:\",wandb.run.dir)\n","  atari_env = Atari_Env(\"SpaceInvaders-v0\", NO_OP_STEPS)\n","  experience_memory = PrioritizedExperienceReplay(max_size=EXPERIENCE_REPLAY_MAX_SIZE, train_min_frames=EXPERIENCE_REPLAY_MIN_SIZE, train_max_frames=MAX_FRAMES, batch_size=BATCH_SIZE)  \n","  epsilon_greedy = epsilonGreedy(replay_min_frames=EXPERIENCE_REPLAY_MIN_SIZE, replay_max_frames=EXPERIENCE_REPLAY_MAX_SIZE, train_max_frames=MAX_FRAMES)\n","  main_dqn = DuelingDoubleDQN(epsilon_greedy, atari_env.env.action_space.n, hidden_units=HIDDEN, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n","  target_dqn = DuelingDoubleDQN(epsilon_greedy, atari_env.env.action_space.n, hidden_units=HIDDEN, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n","  frame_nos = 0\n","  total_train_rewards = []\n","  total_train_loss = []\n","\n","  while frame_nos < MAX_FRAMES:\n","    epoch_frame = 0\n","    while epoch_frame < EVALUATION_FREQUENCY:\n","      ### TRAINING ###\n","      terminal_life_lost = atari_env.reset(evaluation=False)\n","      episode_reward = 0\n","      episode_loss = 0\n","      for _ in range(MAX_EPISODE_FRAMES):\n","        action, predicted_Q = main_dqn.get_action(atari_env.state, frame_nos, evaluation=False)\n","        old_state = atari_env.state\n","        processed_new_frame, reward, terminal, terminal_life_lost, _ = atari_env.step(action)\n","        frame_nos += 1\n","        epoch_frame += 1\n","        episode_reward += reward        \n","\n","        if frame_nos % UPDATE_FREQ == 0 and frame_nos > EXPERIENCE_REPLAY_MIN_SIZE:\n","          loss = train_main_dqn(main_dqn, target_dqn, experience_memory, batch_size=BATCH_SIZE, gamma=GAMMA, frame_nos=frame_nos)          \n","          episode_loss += loss.numpy()\n","\n","        if frame_nos < EXPERIENCE_REPLAY_MIN_SIZE:\n","          experience_memory.add_experience(processed_new_frame[:,:,0], action, clip_reward(reward), terminal_life_lost, reward)\n","        else:\n","          if predicted_Q is None:\n","            predicted_Q = main_dqn.get_Q_values(np.expand_dims(old_state, axis=0)) \n","          target_Q = get_target_Q(main_dqn, target_dqn, batch_size=1, gamma=GAMMA, new_states=np.expand_dims(atari_env.state, axis=0), rewards=reward, terminal_flags=terminal)\n","          td_error = get_td_error(target_Q, predicted_Q, [action], batch_size=1)\n","          experience_memory.add_experience(processed_new_frame[:,:,0], action, clip_reward(reward), terminal_life_lost, td_error[0])\n","        \n","        if frame_nos % TARGET_NETWORK_UPDATE_FREQ and frame_nos > EXPERIENCE_REPLAY_MIN_SIZE:\n","          target_dqn.copy_weights(main_dqn)\n","\n","        if terminal:\n","          terminal = False\n","          break\n","\n","      total_train_rewards.append(episode_reward)\n","      total_train_loss.append(episode_loss)\n","      #print(\"Train Episode:\", len(total_train_rewards), \"frame_nos:\", frame_nos,\"episode_reward:\", episode_reward, \"episode_loss:\",episode_loss)\n","\n","    ### EVALUATION ###\n","    terminal = True\n","    total_eval_rewards = []\n","    for _ in range(EVALUATION_STEPS):\n","      if terminal:\n","        terminal_life_lost = atari_env.reset(evaluation=True)\n","        episode_reward = 0\n","        terminal = False\n","\n","      action, _ = main_dqn.get_action(atari_env.state, frame_nos, evaluation=True)\n","      processed_new_frame, reward, terminal, terminal_life_lost, _ = atari_env.step(action)\n","      episode_reward += reward\n","\n","      if terminal:\n","        total_eval_rewards.append(episode_reward)        \n","        print(\"Eval Episode:\", len(total_eval_rewards), \"Episode Reward:\", episode_reward, \"Avg Reward:\", np.mean(total_eval_rewards))\n","\n","    wandb.log({'cumulative_avg_reward': np.mean(total_eval_rewards)})\n","    # Save model on gdrive\n","    print(\"Saving model at frame nos:\",frame_nos)\n","    gdrive_model_name = 'DDDQN_Model_PER_Final'\n","    main_dqn.save_model(\"/content/gdrive/My Drive/\" + gdrive_model_name)\n","\n","  # Save model on wandb\n","  main_dqn.save_model(os.path.join(wandb.run.dir,gdrive_model_name))\n","\n","execute_training()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://app.wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/raghmura/qualcomm\" target=\"_blank\">https://app.wandb.ai/raghmura/qualcomm</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/raghmura/qualcomm/runs/1b578d1f\" target=\"_blank\">https://app.wandb.ai/raghmura/qualcomm/runs/1b578d1f</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Wandb Run Dir: /content/wandb/run-20200425_214307-1b578d1f\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/envs/atari/atari_env.py:113: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n","  action = self._action_set[a]\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Episode: 1 Episode Reward: 125.0 Avg Reward: 125.0\n","Eval Episode: 2 Episode Reward: 210.0 Avg Reward: 167.5\n","Eval Episode: 3 Episode Reward: 275.0 Avg Reward: 203.33333333333334\n","Eval Episode: 4 Episode Reward: 200.0 Avg Reward: 202.5\n","Eval Episode: 5 Episode Reward: 350.0 Avg Reward: 232.0\n","Eval Episode: 6 Episode Reward: 110.0 Avg Reward: 211.66666666666666\n","Eval Episode: 7 Episode Reward: 180.0 Avg Reward: 207.14285714285714\n","Eval Episode: 8 Episode Reward: 145.0 Avg Reward: 199.375\n","Saving model at frame nos: 200550\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 100.0 Avg Reward: 100.0\n","Eval Episode: 2 Episode Reward: 95.0 Avg Reward: 97.5\n","Eval Episode: 3 Episode Reward: 145.0 Avg Reward: 113.33333333333333\n","Eval Episode: 4 Episode Reward: 80.0 Avg Reward: 105.0\n","Eval Episode: 5 Episode Reward: 195.0 Avg Reward: 123.0\n","Eval Episode: 6 Episode Reward: 45.0 Avg Reward: 110.0\n","Eval Episode: 7 Episode Reward: 90.0 Avg Reward: 107.14285714285714\n","Eval Episode: 8 Episode Reward: 65.0 Avg Reward: 101.875\n","Eval Episode: 9 Episode Reward: 120.0 Avg Reward: 103.88888888888889\n","Eval Episode: 10 Episode Reward: 80.0 Avg Reward: 101.5\n","Eval Episode: 11 Episode Reward: 45.0 Avg Reward: 96.36363636363636\n","Eval Episode: 12 Episode Reward: 150.0 Avg Reward: 100.83333333333333\n","Eval Episode: 13 Episode Reward: 185.0 Avg Reward: 107.3076923076923\n","Eval Episode: 14 Episode Reward: 30.0 Avg Reward: 101.78571428571429\n","Saving model at frame nos: 400867\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 180.0 Avg Reward: 180.0\n","Eval Episode: 2 Episode Reward: 85.0 Avg Reward: 132.5\n","Eval Episode: 3 Episode Reward: 80.0 Avg Reward: 115.0\n","Eval Episode: 4 Episode Reward: 280.0 Avg Reward: 156.25\n","Eval Episode: 5 Episode Reward: 65.0 Avg Reward: 138.0\n","Eval Episode: 6 Episode Reward: 120.0 Avg Reward: 135.0\n","Eval Episode: 7 Episode Reward: 185.0 Avg Reward: 142.14285714285714\n","Eval Episode: 8 Episode Reward: 115.0 Avg Reward: 138.75\n","Eval Episode: 9 Episode Reward: 80.0 Avg Reward: 132.22222222222223\n","Eval Episode: 10 Episode Reward: 70.0 Avg Reward: 126.0\n","Eval Episode: 11 Episode Reward: 65.0 Avg Reward: 120.45454545454545\n","Eval Episode: 12 Episode Reward: 110.0 Avg Reward: 119.58333333333333\n","Eval Episode: 13 Episode Reward: 110.0 Avg Reward: 118.84615384615384\n","Eval Episode: 14 Episode Reward: 30.0 Avg Reward: 112.5\n","Saving model at frame nos: 601840\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 300.0 Avg Reward: 300.0\n","Eval Episode: 2 Episode Reward: 95.0 Avg Reward: 197.5\n","Eval Episode: 3 Episode Reward: 120.0 Avg Reward: 171.66666666666666\n","Eval Episode: 4 Episode Reward: 165.0 Avg Reward: 170.0\n","Eval Episode: 5 Episode Reward: 140.0 Avg Reward: 164.0\n","Eval Episode: 6 Episode Reward: 160.0 Avg Reward: 163.33333333333334\n","Eval Episode: 7 Episode Reward: 200.0 Avg Reward: 168.57142857142858\n","Eval Episode: 8 Episode Reward: 330.0 Avg Reward: 188.75\n","Eval Episode: 9 Episode Reward: 85.0 Avg Reward: 177.22222222222223\n","Eval Episode: 10 Episode Reward: 220.0 Avg Reward: 181.5\n","Saving model at frame nos: 802096\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 310.0 Avg Reward: 310.0\n","Eval Episode: 2 Episode Reward: 60.0 Avg Reward: 185.0\n","Eval Episode: 3 Episode Reward: 290.0 Avg Reward: 220.0\n","Eval Episode: 4 Episode Reward: 265.0 Avg Reward: 231.25\n","Eval Episode: 5 Episode Reward: 65.0 Avg Reward: 198.0\n","Eval Episode: 6 Episode Reward: 370.0 Avg Reward: 226.66666666666666\n","Eval Episode: 7 Episode Reward: 250.0 Avg Reward: 230.0\n","Eval Episode: 8 Episode Reward: 200.0 Avg Reward: 226.25\n","Eval Episode: 9 Episode Reward: 390.0 Avg Reward: 244.44444444444446\n","Eval Episode: 10 Episode Reward: 105.0 Avg Reward: 230.5\n","Eval Episode: 11 Episode Reward: 340.0 Avg Reward: 240.45454545454547\n","Saving model at frame nos: 1002350\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 195.0 Avg Reward: 195.0\n","Eval Episode: 2 Episode Reward: 255.0 Avg Reward: 225.0\n","Eval Episode: 3 Episode Reward: 290.0 Avg Reward: 246.66666666666666\n","Eval Episode: 4 Episode Reward: 570.0 Avg Reward: 327.5\n","Eval Episode: 5 Episode Reward: 110.0 Avg Reward: 284.0\n","Eval Episode: 6 Episode Reward: 275.0 Avg Reward: 282.5\n","Eval Episode: 7 Episode Reward: 320.0 Avg Reward: 287.85714285714283\n","Eval Episode: 8 Episode Reward: 55.0 Avg Reward: 258.75\n","Eval Episode: 9 Episode Reward: 195.0 Avg Reward: 251.66666666666666\n","Eval Episode: 10 Episode Reward: 285.0 Avg Reward: 255.0\n","Saving model at frame nos: 1203149\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n"],"name":"stdout"},{"output_type":"stream","text":["requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/raghmura/qualcomm/1b578d1f/file_stream. args: ('https://api.wandb.ai/files/raghmura/qualcomm/1b578d1f/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 1082, 'content': ['{\"system.gpu.0.gpu\": 11.33, \"system.gpu.0.memory\": 1.0, \"system.gpu.0.memoryAllocated\": 4.26, \"system.gpu.0.temp\": 41.0, \"system.gpu.0.powerWatts\": 34.97, \"system.gpu.0.powerPercent\": 13.99, \"system.cpu\": 54.82, \"system.memory\": 72.29, \"system.disk\": 48.3, \"system.proc.memory.availableMB\": 3612.62, \"system.proc.memory.rssMB\": 9473.86, \"system.proc.memory.percent\": 72.76, \"system.proc.cpu.threads\": 34.0, \"system.network.sent\": 43420809, \"system.network.recv\": 7806662, \"_wandb\": true, \"_timestamp\": 1587886901, \"_runtime\": 36131}\\n']}}}}\n","requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/raghmura/qualcomm/1b578d1f/file_stream. args: ('https://api.wandb.ai/files/raghmura/qualcomm/1b578d1f/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 1082, 'content': ['{\"system.gpu.0.gpu\": 11.33, \"system.gpu.0.memory\": 1.0, \"system.gpu.0.memoryAllocated\": 4.26, \"system.gpu.0.temp\": 41.0, \"system.gpu.0.powerWatts\": 34.97, \"system.gpu.0.powerPercent\": 13.99, \"system.cpu\": 54.82, \"system.memory\": 72.29, \"system.disk\": 48.3, \"system.proc.memory.availableMB\": 3612.62, \"system.proc.memory.rssMB\": 9473.86, \"system.proc.memory.percent\": 72.76, \"system.proc.cpu.threads\": 34.0, \"system.network.sent\": 43420809, \"system.network.recv\": 7806662, \"_wandb\": true, \"_timestamp\": 1587886901, \"_runtime\": 36131}\\n']}}}}\n"],"name":"stderr"},{"output_type":"stream","text":["Eval Episode: 1 Episode Reward: 540.0 Avg Reward: 540.0\n","Eval Episode: 2 Episode Reward: 100.0 Avg Reward: 320.0\n","Eval Episode: 3 Episode Reward: 60.0 Avg Reward: 233.33333333333334\n","Eval Episode: 4 Episode Reward: 115.0 Avg Reward: 203.75\n","Eval Episode: 5 Episode Reward: 105.0 Avg Reward: 184.0\n","Eval Episode: 6 Episode Reward: 75.0 Avg Reward: 165.83333333333334\n","Eval Episode: 7 Episode Reward: 195.0 Avg Reward: 170.0\n","Eval Episode: 8 Episode Reward: 250.0 Avg Reward: 180.0\n","Eval Episode: 9 Episode Reward: 130.0 Avg Reward: 174.44444444444446\n","Eval Episode: 10 Episode Reward: 80.0 Avg Reward: 165.0\n","Eval Episode: 11 Episode Reward: 320.0 Avg Reward: 179.0909090909091\n","Eval Episode: 12 Episode Reward: 70.0 Avg Reward: 170.0\n","Saving model at frame nos: 1403366\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 320.0 Avg Reward: 320.0\n","Eval Episode: 2 Episode Reward: 530.0 Avg Reward: 425.0\n","Eval Episode: 3 Episode Reward: 130.0 Avg Reward: 326.6666666666667\n","Eval Episode: 4 Episode Reward: 85.0 Avg Reward: 266.25\n","Eval Episode: 5 Episode Reward: 155.0 Avg Reward: 244.0\n","Eval Episode: 6 Episode Reward: 135.0 Avg Reward: 225.83333333333334\n","Eval Episode: 7 Episode Reward: 460.0 Avg Reward: 259.2857142857143\n","Eval Episode: 8 Episode Reward: 155.0 Avg Reward: 246.25\n","Eval Episode: 9 Episode Reward: 430.0 Avg Reward: 266.6666666666667\n","Eval Episode: 10 Episode Reward: 250.0 Avg Reward: 265.0\n","Eval Episode: 11 Episode Reward: 465.0 Avg Reward: 283.1818181818182\n","Saving model at frame nos: 1603576\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 370.0 Avg Reward: 370.0\n","Eval Episode: 2 Episode Reward: 175.0 Avg Reward: 272.5\n","Eval Episode: 3 Episode Reward: 370.0 Avg Reward: 305.0\n","Eval Episode: 4 Episode Reward: 360.0 Avg Reward: 318.75\n","Eval Episode: 5 Episode Reward: 75.0 Avg Reward: 270.0\n","Eval Episode: 6 Episode Reward: 120.0 Avg Reward: 245.0\n","Eval Episode: 7 Episode Reward: 240.0 Avg Reward: 244.28571428571428\n","Eval Episode: 8 Episode Reward: 470.0 Avg Reward: 272.5\n","Eval Episode: 9 Episode Reward: 50.0 Avg Reward: 247.77777777777777\n","Eval Episode: 10 Episode Reward: 55.0 Avg Reward: 228.5\n","Eval Episode: 11 Episode Reward: 110.0 Avg Reward: 217.72727272727272\n","Eval Episode: 12 Episode Reward: 80.0 Avg Reward: 206.25\n","Saving model at frame nos: 1803797\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 90.0 Avg Reward: 90.0\n","Eval Episode: 2 Episode Reward: 325.0 Avg Reward: 207.5\n","Eval Episode: 3 Episode Reward: 320.0 Avg Reward: 245.0\n","Eval Episode: 4 Episode Reward: 155.0 Avg Reward: 222.5\n","Eval Episode: 5 Episode Reward: 165.0 Avg Reward: 211.0\n","Eval Episode: 6 Episode Reward: 190.0 Avg Reward: 207.5\n","Eval Episode: 7 Episode Reward: 325.0 Avg Reward: 224.28571428571428\n","Eval Episode: 8 Episode Reward: 155.0 Avg Reward: 215.625\n","Eval Episode: 9 Episode Reward: 95.0 Avg Reward: 202.22222222222223\n","Eval Episode: 10 Episode Reward: 50.0 Avg Reward: 187.0\n","Eval Episode: 11 Episode Reward: 80.0 Avg Reward: 177.27272727272728\n","Eval Episode: 12 Episode Reward: 50.0 Avg Reward: 166.66666666666666\n","Eval Episode: 13 Episode Reward: 185.0 Avg Reward: 168.07692307692307\n","Saving model at frame nos: 2003832\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 140.0 Avg Reward: 140.0\n","Eval Episode: 2 Episode Reward: 165.0 Avg Reward: 152.5\n","Eval Episode: 3 Episode Reward: 305.0 Avg Reward: 203.33333333333334\n","Eval Episode: 4 Episode Reward: 280.0 Avg Reward: 222.5\n","Eval Episode: 5 Episode Reward: 230.0 Avg Reward: 224.0\n","Eval Episode: 6 Episode Reward: 145.0 Avg Reward: 210.83333333333334\n","Eval Episode: 7 Episode Reward: 220.0 Avg Reward: 212.14285714285714\n","Eval Episode: 8 Episode Reward: 295.0 Avg Reward: 222.5\n","Eval Episode: 9 Episode Reward: 115.0 Avg Reward: 210.55555555555554\n","Eval Episode: 10 Episode Reward: 80.0 Avg Reward: 197.5\n","Eval Episode: 11 Episode Reward: 120.0 Avg Reward: 190.45454545454547\n","Eval Episode: 12 Episode Reward: 280.0 Avg Reward: 197.91666666666666\n","Saving model at frame nos: 2204274\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 685.0 Avg Reward: 685.0\n","Eval Episode: 2 Episode Reward: 200.0 Avg Reward: 442.5\n","Eval Episode: 3 Episode Reward: 250.0 Avg Reward: 378.3333333333333\n","Eval Episode: 4 Episode Reward: 65.0 Avg Reward: 300.0\n","Eval Episode: 5 Episode Reward: 210.0 Avg Reward: 282.0\n","Eval Episode: 6 Episode Reward: 285.0 Avg Reward: 282.5\n","Eval Episode: 7 Episode Reward: 195.0 Avg Reward: 270.0\n","Eval Episode: 8 Episode Reward: 525.0 Avg Reward: 301.875\n","Eval Episode: 9 Episode Reward: 60.0 Avg Reward: 275.0\n","Eval Episode: 10 Episode Reward: 465.0 Avg Reward: 294.0\n","Saving model at frame nos: 2404876\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 205.0 Avg Reward: 205.0\n","Eval Episode: 2 Episode Reward: 315.0 Avg Reward: 260.0\n","Eval Episode: 3 Episode Reward: 65.0 Avg Reward: 195.0\n","Eval Episode: 4 Episode Reward: 365.0 Avg Reward: 237.5\n","Eval Episode: 5 Episode Reward: 515.0 Avg Reward: 293.0\n","Eval Episode: 6 Episode Reward: 125.0 Avg Reward: 265.0\n","Eval Episode: 7 Episode Reward: 140.0 Avg Reward: 247.14285714285714\n","Eval Episode: 8 Episode Reward: 200.0 Avg Reward: 241.25\n","Eval Episode: 9 Episode Reward: 820.0 Avg Reward: 305.55555555555554\n","Eval Episode: 10 Episode Reward: 205.0 Avg Reward: 295.5\n","Eval Episode: 11 Episode Reward: 65.0 Avg Reward: 274.54545454545456\n","Eval Episode: 12 Episode Reward: 240.0 Avg Reward: 271.6666666666667\n","Saving model at frame nos: 2605050\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 80.0 Avg Reward: 80.0\n","Eval Episode: 2 Episode Reward: 405.0 Avg Reward: 242.5\n","Eval Episode: 3 Episode Reward: 160.0 Avg Reward: 215.0\n","Eval Episode: 4 Episode Reward: 255.0 Avg Reward: 225.0\n","Eval Episode: 5 Episode Reward: 225.0 Avg Reward: 225.0\n","Eval Episode: 6 Episode Reward: 195.0 Avg Reward: 220.0\n","Eval Episode: 7 Episode Reward: 260.0 Avg Reward: 225.71428571428572\n","Eval Episode: 8 Episode Reward: 150.0 Avg Reward: 216.25\n","Eval Episode: 9 Episode Reward: 355.0 Avg Reward: 231.66666666666666\n","Eval Episode: 10 Episode Reward: 160.0 Avg Reward: 224.5\n","Eval Episode: 11 Episode Reward: 235.0 Avg Reward: 225.45454545454547\n","Saving model at frame nos: 2805460\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","Eval Episode: 1 Episode Reward: 35.0 Avg Reward: 35.0\n","Eval Episode: 2 Episode Reward: 310.0 Avg Reward: 172.5\n","Eval Episode: 3 Episode Reward: 125.0 Avg Reward: 156.66666666666666\n","Eval Episode: 4 Episode Reward: 495.0 Avg Reward: 241.25\n","Eval Episode: 5 Episode Reward: 45.0 Avg Reward: 202.0\n","Eval Episode: 6 Episode Reward: 140.0 Avg Reward: 191.66666666666666\n","Eval Episode: 7 Episode Reward: 5.0 Avg Reward: 165.0\n","Eval Episode: 8 Episode Reward: 270.0 Avg Reward: 178.125\n","Eval Episode: 9 Episode Reward: 35.0 Avg Reward: 162.22222222222223\n","Eval Episode: 10 Episode Reward: 5.0 Avg Reward: 146.5\n","Eval Episode: 11 Episode Reward: 65.0 Avg Reward: 139.0909090909091\n","Eval Episode: 12 Episode Reward: 110.0 Avg Reward: 136.66666666666666\n","Saving model at frame nos: 3005517\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/DDDQN_Model_PER_Final/assets\n","INFO:tensorflow:Assets written to: /content/wandb/run-20200425_214307-1b578d1f/DDDQN_Model_PER_Final/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VC-_TjCgSbsE","colab_type":"text"},"source":["The below code block to be used to evaluate the trained model -"]},{"cell_type":"code","metadata":{"id":"bXrq4Xg2fq2w","colab_type":"code","colab":{}},"source":["# **** Caution: Do not modify this cell ****\n","# initialize total reward across episodes\n","cumulative_reward = 0\n","episode = 0\n","\n","def evaluate(episodic_reward, reset=False):\n","  '''\n","  Takes in the reward for an episode, calculates the cumulative_avg_reward\n","    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n","    Called after playing each episode. See example below.\n","\n","  Arguments:\n","    episodic_reward - reward received after playing current episode\n","  '''\n","  global episode\n","  global cumulative_reward\n","  if reset:\n","    cumulative_reward = 0\n","    episode = 0\n","    \n","  episode += 1\n","  print(\"Episode: %d\"%(episode))\n","\n","  # your models will be evaluated on 100-episode average reward\n","  # therefore, we stop logging after 100 episodes\n","  if (episode > 100):\n","    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n","    return\n","\n","  # log total reward received in this episode to wandb\n","  wandb.log({'episodic_reward': episodic_reward})\n","  print(\"episodic_reward \", episodic_reward)\n","\n","  # add reward from this episode to cumulative_reward\n","  cumulative_reward += episodic_reward\n","\n","  # calculate the cumulative_avg_reward\n","  # this is the metric your models will be evaluated on\n","  cumulative_avg_reward = cumulative_reward/episode\n","\n","  # log cumulative_avg_reward over all episodes played so far\n","  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})\n","  print('cumulative_avg_reward ', cumulative_avg_reward)\n","\n","  return cumulative_avg_reward"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXO34HzwFSSe","colab_type":"code","outputId":"2ef43ba4-7ddf-4d82-b264-fd0adbe7e4aa","executionInfo":{"status":"ok","timestamp":1588285361788,"user_tz":420,"elapsed":275475,"user":{"displayName":"Raghav M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNe2ZEunNPBUP_Y4RZlYD9ZQJ9kY_vmiIYUTyY=s64","userId":"05654575933181341194"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1B-J0xDe9_Cy8eTv4xp-MD87A1irLdEGH"}},"source":["from numpy.random import seed\n","\n","cumulative_avg_rewards = []\n","total_episode_rewards = {}\n","total_avg_rewards = {}\n","for seed_ in [100]:\n","  log_name_1 = \"episode_reward-\" + str(seed_)\n","  log_name_2 = \"cumulative_avg_reward-\" + str(seed_)\n","  seed_run_episode_reward = []\n","  seed_run_avg_rewards = []\n","  seed(seed_)\n","  tf.random.set_seed(seed_)\n","  print(\"Seed: \",seed_)\n","\n","  # Load the trained model\n","  atari_env = Atari_Env(\"SpaceInvaders-v0\", NO_OP_STEPS)  \n","  epsilon_greedy = epsilonGreedy(replay_min_frames=EXPERIENCE_REPLAY_MIN_SIZE, replay_max_frames=EXPERIENCE_REPLAY_MAX_SIZE, train_max_frames=MAX_FRAMES)\n","  trained_dqn = DuelingDoubleDQN(epsilon_greedy, atari_env.env.action_space.n, hidden_units=HIDDEN, learning_rate=LEARNING_RATE)   \n","  # load the model\n","  model_name = \"/content/gdrive/My Drive/DDDQN_Model_PER_Final\"\n","  trained_dqn.load_model(model_name)\n","\n","  # initialize a new wandb run\n","  wandb.init(project=\"qualcomm\")\n","  print(\"Wandb Run Dir:\",wandb.run.dir)\n","\n","  # define hyperparameters\n","  wandb.config.episodes = 100  \n","\n","  # record gameplay video\n","  display = Display(visible=0, size=(1400, 900))\n","  display.start()\n","\n","  highest_score = 0\n","  total_Q = np.zeros([6])\n","  q_values = np.zeros([6])\n","  # run for 100 episodes\n","  for i in range(wandb.config.episodes):  \n","  #for i in range(100):  \n","    # Set reward received in this episode = 0 at the start of the episode\n","    episodic_reward = 0\n","    reset = False\n","\n","    # record a video of the game using wrapper\n","    atari_env.env = gym.wrappers.Monitor(atari_env.env, './video', force=True)        \n","\n","    terminal = False\n","    state = atari_env.eval_reset()\n","    action_count = 0\n","    while not terminal:\n","      # get prediction for next action from model            \n","      action, q_vals = trained_dqn.get_action(state, 0, evaluation=True)      \n","      state, reward, terminal = atari_env.eval_step(action, frame_skip=3)      \n","      episodic_reward += reward\n","      action_count += 1           \n","      q_values += q_vals.numpy()[0]    \n","    q_values = q_values / action_count\n","    total_Q += q_values\n","    q_values = np.zeros([6])\n","      \n","    # call evaluation function - takes in reward received after playing an episode\n","    # calculates the cumulative_avg_reward over 100 episodes & logs it in wandb\n","    if(i==0):\n","      reset = True\n","\n","    cumulative_avg_reward = evaluate(episodic_reward, reset)    \n","    seed_run_episode_reward.append(episodic_reward)\n","    seed_run_avg_rewards.append(cumulative_avg_reward)\n","    # your models will be evaluated on 100-episode average reward\n","    # therefore, we stop logging after 100 episodes\n","    if (i >= 99):\n","      cumulative_avg_rewards.append(cumulative_avg_reward)      \n","      break\n","  \n","    atari_env.env.close()\n","\n","    # render gameplay video, if the scrore is higher than previous recorded video's score\n","    if (highest_score < episodic_reward): \n","      highest_score = episodic_reward   \n","      mp4list = glob.glob('video/*.mp4')\n","      if len(mp4list) > 0:\n","        print(len(mp4list))\n","        mp4 = mp4list[-1]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","\n","        # log gameplay video in wandb\n","        gameplay = \"gameplay-\"  + str(seed_)\n","        wandb.log({gameplay: wandb.Video(mp4, fps=4, format=\"gif\")})\n","\n","        # display gameplay video\n","        ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n","                    loop controls style=\"height: 400px;\">\n","                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","                </video>'''.format(encoded.decode('ascii'))))        \n","    \n","total_Q = total_Q / wandb.config.episodes    \n","for q in range(atari_env.env.action_space.n):\n","  wandb.log({'Avg_Q_Values': total_Q[q]})           "],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}